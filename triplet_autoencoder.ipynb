{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:23:03.400907Z",
     "start_time": "2024-05-18T08:23:03.384930Z"
    }
   },
   "id": "cbd32ee2196f8464",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TripletGestureDataset(Dataset):\n",
    "    fingers = [\n",
    "        [0, 1, 2, 3, 4],\n",
    "        [0, 5, 6, 7, 8],\n",
    "        [0, 9, 10, 11, 12],\n",
    "        [0, 13, 14, 15, 16],\n",
    "        [0, 17, 18, 19, 20]\n",
    "    ]\n",
    "\n",
    "    def __init__(self, data: np.ndarray, labels: np.ndarray):\n",
    "        \"\"\"\n",
    "        初始化函数。\n",
    "        :param data: 形状为(n, 21, 3)的numpy数组，n为样本数量。\n",
    "        :param labels: 形状为(n, num_classes)的numpy数组，每个标签为one-hot编码。\n",
    "        \"\"\"\n",
    "\n",
    "        # ## 数据增强\n",
    "        # data = np.abs(data)\n",
    "        # data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "        ## add the two nearby length in each finger\n",
    "        for finger in self.fingers:\n",
    "            for i in range(len(finger) - 1):\n",
    "                dist = data[:, finger[i + 1]] - data[:, finger[i]]\n",
    "                # add a new dimension\n",
    "                dist = np.expand_dims(dist, axis=1)\n",
    "                data = np.concatenate((data, dist), axis=1)\n",
    "\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        # 将one-hot编码的标签转换为类别索引\n",
    "        self.labels = np.argmax(labels, axis=1)\n",
    "        # 预计算每个类别的索引列表，以便快速随机选择样本\n",
    "        self.indices = [np.where(self.labels == i)[0] for i in np.unique(self.labels)]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集中的样本数。\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        从数据集中获取一个样本及其正例和负例。\n",
    "        :param idx: 锚点样本的索引。\n",
    "        \"\"\"\n",
    "        anchor = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 选择正例，即同一类别中的另一个样本\n",
    "        positive_index = idx\n",
    "        while positive_index == idx:  # 确保正例不是锚点本身\n",
    "            positive_index = np.random.choice(self.indices[label])\n",
    "        positive = self.data[positive_index]\n",
    "\n",
    "        # 选择负例，即不同类别的样本\n",
    "        negative_label = np.random.choice([l for l in range(len(self.indices)) if l != label])\n",
    "        negative_index = np.random.choice(self.indices[negative_label])\n",
    "        negative = self.data[negative_index]\n",
    "\n",
    "        return anchor, positive, negative, label\n",
    "\n",
    "    def get_input_dim(self):\n",
    "        return self.data.shape[1] * self.data.shape[2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:23:03.430916Z",
     "start_time": "2024-05-18T08:23:03.416908Z"
    }
   },
   "id": "d862753b4f984735",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "## load the data\n",
    "raw_data = np.load('./dataset/8class_dataset_100k.npz')\n",
    "train_data, train_label, test_data, test_label = raw_data['train_data'], raw_data['train_label'], raw_data['test_data'], \\\n",
    "    raw_data['test_label']\n",
    "\n",
    "train_dataset = TripletGestureDataset(train_data, train_label)\n",
    "test_dataset = TripletGestureDataset(test_data, test_label)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "data_dim = train_dataset.get_input_dim()\n",
    "print(data_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:23:04.705528Z",
     "start_time": "2024-05-18T08:23:03.448432Z"
    }
   },
   "id": "ea496ccd7d2a1a1e",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# 初始化模型, 损失函数, 和优化器\n",
    "class TripletAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=2):\n",
    "        super(TripletAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, latent_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 128),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TripletAutoencoder(input_dim=data_dim, latent_dim=2).to(device)\n",
    "\n",
    "reconstruction_loss = nn.MSELoss()\n",
    "triplet_loss = nn.TripletMarginLoss(margin=1.0)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:23:04.737109Z",
     "start_time": "2024-05-18T08:23:04.722575Z"
    }
   },
   "id": "d84fea01cd07c315",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [1024, 128]          15,872\n",
      "              ReLU-2                [1024, 128]               0\n",
      "            Linear-3                [1024, 256]          33,024\n",
      "              ReLU-4                [1024, 256]               0\n",
      "            Linear-5                  [1024, 2]             514\n",
      "            Linear-6                [1024, 256]             768\n",
      "              ReLU-7                [1024, 256]               0\n",
      "            Linear-8                [1024, 128]          32,896\n",
      "              ReLU-9                [1024, 128]               0\n",
      "           Linear-10                [1024, 123]          15,867\n",
      "             Tanh-11                [1024, 123]               0\n",
      "================================================================\n",
      "Total params: 98,941\n",
      "Trainable params: 98,941\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.48\n",
      "Forward/backward pass size (MB): 13.94\n",
      "Params size (MB): 0.38\n",
      "Estimated Total Size (MB): 14.80\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## summary the model\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (data_dim,), 1024, \"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:23:04.769112Z",
     "start_time": "2024-05-18T08:23:04.754096Z"
    }
   },
   "id": "fa7ccc32d6b2ce93",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch 1/10:   0%|          | 0/98 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "564cf253f9f74265aa614f282a13bdac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 2/10:   0%|          | 0/98 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3100ddf4d7234f999037e6fdb9314700"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 3/10:   0%|          | 0/98 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c0e82380d0b4d8992b7a4cd9944fe35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 4/10:   0%|          | 0/98 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ab51d3efe1f4b8eb28d0d320f6387ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 5/10:   0%|          | 0/98 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4989ca5d7924a56b5c457e09b7935da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 6/10:   0%|          | 0/98 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2ba57f240bc4c2280aa1e3ea14ceb29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 7/10:   0%|          | 0/98 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a206ee6ff0e4d448f41b31bb57af34e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 8/10:   0%|          | 0/98 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bc98d1452ab4a9a840184866b7917d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 9/10:   0%|          | 0/98 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6017adb5b0942cd937906b63a40f9bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Epoch 10/10:   0%|          | 0/98 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46f7f721ebff42449ff64b0b1af8f31a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model.train()\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    total_loss = 0\n",
    "    total_r_loss = 0\n",
    "    total_t_loss = 0\n",
    "\n",
    "    for anchors, positives, negatives, _ in progress_bar:\n",
    "        # 将数据移动到GPU上\n",
    "        anchors, positives, negatives = anchors.to(device), positives.to(device), negatives.to(device)\n",
    "\n",
    "        # 将数据展平\n",
    "        anchors, positives, negatives = anchors.view(anchors.size(0), -1), positives.view(positives.size(0),\n",
    "                                                                                          -1), negatives.view(\n",
    "            negatives.size(0), -1)\n",
    "\n",
    "        # 获取编码和解码的输出\n",
    "        anchor_encoded, anchor_decoded = model(anchors)\n",
    "        positive_encoded, _ = model(positives)\n",
    "        negative_encoded, _ = model(negatives)\n",
    "\n",
    "        # 计算重构损失和Triplet损失\n",
    "        r_loss = reconstruction_loss(anchor_decoded, anchors)\n",
    "        t_loss = triplet_loss(anchor_encoded, positive_encoded, negative_encoded)\n",
    "        loss = r_loss + t_loss\n",
    "        # loss = t_loss\n",
    "        # loss = r_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累计损失用于计算平均损失\n",
    "        total_loss += loss.item()\n",
    "        total_r_loss += r_loss.item()\n",
    "        total_t_loss += t_loss.item()\n",
    "\n",
    "        progress_bar.desc = f\"Epoch {epoch + 1}/{num_epochs}\"\n",
    "        progress_bar.set_postfix({\n",
    "            'total_loss': f'{total_loss / (progress_bar.n + 1):.4f}',\n",
    "            'recon_loss': f'{total_r_loss / (progress_bar.n + 1):.4f}',\n",
    "            'triplet_loss': f'{total_t_loss / (progress_bar.n + 1):.4f}'\n",
    "        })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:23:59.797118Z",
     "start_time": "2024-05-18T08:23:04.785109Z"
    }
   },
   "id": "db75d1bef3ec515",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2) (50000,)\n"
     ]
    }
   ],
   "source": [
    "## run the test samples through the encoder\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_labels = []\n",
    "test_latent = []\n",
    "\n",
    "for inputs, _, _, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    inputs = inputs.view(-1, data_dim)\n",
    "    outputs = model.encoder(inputs)\n",
    "    test_latent.append(outputs.cpu().detach().numpy())\n",
    "    test_labels.append(labels.cpu().detach().numpy())\n",
    "\n",
    "test_latent = np.concatenate(test_latent, axis=0)\n",
    "test_labels = np.concatenate(test_labels, axis=0)\n",
    "\n",
    "print(test_latent.shape, test_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:24:01.238446Z",
     "start_time": "2024-05-18T08:23:59.814098Z"
    }
   },
   "id": "6a7511c7394a7ae5",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## calculate the centroid of each class\n",
    "\n",
    "centroids = np.zeros((11, 2))\n",
    "for i in range(11):\n",
    "    idx = test_labels == i\n",
    "    centroids[i] = np.mean(test_latent[idx], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:24:01.270465Z",
     "start_time": "2024-05-18T08:24:01.255447Z"
    }
   },
   "id": "110bb36acad94271",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## plot the latent space\n",
    "%matplotlib tk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = np.unique(test_labels)\n",
    "label_map = {\n",
    "    0: 'call',\n",
    "    1: 'dislike',\n",
    "    2: 'fist',\n",
    "    3: 'like',\n",
    "    4: 'ok',\n",
    "    5: 'one',\n",
    "    6: 'palm',\n",
    "    7: 'peace',\n",
    "    8: 'rock',\n",
    "    9: 'three',\n",
    "    10: 'three2',\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title('Latent Space')\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    idx = test_labels == label\n",
    "\n",
    "    ax.scatter(test_latent[idx, 0],\n",
    "               test_latent[idx, 1],\n",
    "               c=np.array(matplotlib.colormaps['tab20'].colors[i]).reshape(1, -1),\n",
    "               label=f\"{label} {label_map[label]}\",\n",
    "               alpha=0.5)\n",
    "\n",
    "    ax.scatter(centroids[i, 0], centroids[i, 1], c='black', marker='x', s=100)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:24:01.459037Z",
     "start_time": "2024-05-18T08:24:01.288040Z"
    }
   },
   "id": "785302e7d68d1c58",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Initialize and fit KMeans\n",
    "kmeans = KMeans(n_clusters=11, random_state=0).fit(test_latent)\n",
    "\n",
    "# Predict the cluster IDs for each data point\n",
    "cluster_ids = kmeans.predict(test_latent)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:24:02.578149Z",
     "start_time": "2024-05-18T08:24:02.526641Z"
    }
   },
   "id": "6ea418b82bf7fd7",
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zkw42\\AppData\\Local\\Temp\\ipykernel_23364\\2515048386.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = matplotlib.cm.get_cmap('tab20', 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.legend.Legend at 0x1c7e5353340>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colors from a colormap\n",
    "colors = matplotlib.cm.get_cmap('tab20', 11)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Latent Space with K-Means Clustering')\n",
    "\n",
    "for cluster in range(11):\n",
    "    idx = cluster_ids == cluster\n",
    "    ax.scatter(test_latent[idx, 0],\n",
    "               test_latent[idx, 1],\n",
    "               c=np.array(matplotlib.colormaps['tab20'].colors[cluster]).reshape(1, -1),\n",
    "               label=f\"Cluster {cluster}\",\n",
    "               alpha=0.5)\n",
    "\n",
    "ax.legend()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:24:02.734859Z",
     "start_time": "2024-05-18T08:24:02.595150Z"
    }
   },
   "id": "4bd672785559fd43",
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Accuracy: 0.8105\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate clustering accuracy\n",
    "# We need to find the best match between cluster labels and true labels\n",
    "def clustering_accuracy(true_labels, cluster_labels):\n",
    "    # Confusion matrix between true labels and cluster labels\n",
    "    matrix = confusion_matrix(true_labels, cluster_labels)\n",
    "    # Summing the highest values in each column of the confusion matrix\n",
    "    max_matches = np.sum(np.max(matrix, axis=0))\n",
    "    accuracy = max_matches / len(true_labels)\n",
    "    return matrix, accuracy\n",
    "\n",
    "\n",
    "# Calculate and print the clustering accuracy\n",
    "matrix, accuracy = clustering_accuracy(test_labels, cluster_ids)\n",
    "print(f\"Clustering Accuracy: {accuracy:.4f}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:24:03.521262Z",
     "start_time": "2024-05-18T08:24:03.509116Z"
    }
   },
   "id": "f22da1acbba90ef1",
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ## save model\n",
    "# torch.save(model.state_dict(), './model/triplet_autoencoder_8934.pth')\n",
    "# \n",
    "# ## save the centroids\n",
    "# np.save('./model/triplet_autoencoder_8934_centroids.npy', centroids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:24:03.536675Z",
     "start_time": "2024-05-18T08:24:03.532668Z"
    }
   },
   "id": "bb074c0ac6fd6da",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T08:24:03.551674Z",
     "start_time": "2024-05-18T08:24:03.547673Z"
    }
   },
   "id": "4c48bf699f9353c",
   "execution_count": 90
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
